{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5e25b6-fc45-4788-9e40-702c93ff4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install required packages (run once per env)\n",
    "\n",
    "!pip -q install tweepy python-dotenv pandas vaderSentiment matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cd4a01-40d2-4fc5-b4f1-ea47c2d1138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import unicodedata\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from dotenv import load_dotenv\n",
    "import tweepy\n",
    "\n",
    "# Load env\n",
    "load_dotenv()\n",
    "BEARER = os.getenv(\"X_BEARER_TOKEN\")\n",
    "if not BEARER:\n",
    "    raise RuntimeError(\"X_BEARER_TOKEN not found. Please create a .env file with X_BEARER_TOKEN.\")\n",
    "client = tweepy.Client(bearer_token=BEARER, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15819e10-ae91-47a6-a3d2-023694b7ba82",
   "metadata": {},
   "source": [
    "# Define search queries\n",
    "We focus on Australian politics. Note the Australian Labor Party is spelled **Labor** (not Labour). You can tweak '''MAX_TWEET_PER_QUERY''', date window, and the keyword lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458c4fa0-20a7-4f30-86bd-a529fea24c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32177/869497423.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  SINCE = (dt.datetime.utcnow() - dt.timedelta(days=DAYS_BACK)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Labor': '((\"Australian Labor Party\") OR ALP OR (\"Labor Australia\") OR (\"Anthony Albanese\") OR Albo OR @AlboMP OR @AustralianLabor OR auspol OR Australia OR Australian OR Canberra OR Parliament) lang:en -is:retweet',\n",
       " 'Liberal': '((\"Liberal Party of Australia\") OR (\"Liberal Australia\") OR LNP OR (\"Coalition Australia\") OR (\"Susan Ley\") OR auspol OR Australia OR Australian OR Canberra OR Parliament) lang:en -is:retweet'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query config\n",
    "MAX_TWEETS_PER_QUERY = 100 # Adjust based on your API tier/limits\n",
    "DAYS_BACK = 30 # Adjust based on period of time, here we are analysing sentiment in the past month\n",
    "LANG = \"en\" # English only\n",
    "\n",
    "SINCE = (dt.datetime.utcnow() - dt.timedelta(days=DAYS_BACK)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# Hastags and Aussie context terms\n",
    "\n",
    "AUS_CONTEXT = [\"auspol\", \"Australia\", \"Australian\", \"Canberra\", \"Parliament\"]\n",
    "\n",
    "# Party-focused keyword sets\n",
    "\n",
    "LABOR_TERMS = [\n",
    "    \"Australian Labor Party\", \"ALP\", \"Labor Australia\", \"Anthony Albanese\", \"Albo\", \"@AlboMP\", \"@AustralianLabor\"\n",
    "]\n",
    "\n",
    "LIBERAL_TERMS = [\n",
    "    \"Liberal Party of Australia\", \"Liberal Australia\", \"LNP\", \"Coalition Australia\", \"Susan Ley\"\n",
    "]\n",
    "\n",
    "def build_query(terms):\n",
    "    # Compose an OR list, exclude retweets, filter by language.\n",
    "    or_block = \" OR \".join([f'(\"{t}\")' if \" \" in t else t for t in terms + AUS_CONTEXT])\n",
    "    # Avoid very common noise words here; you can add -is:reply to limit to original posts\n",
    "    q = f\"({or_block}) lang:{LANG} -is:retweet\"\n",
    "    return q\n",
    "\n",
    "QUERIES = {\n",
    "    \"Labor\": build_query(LABOR_TERMS),\n",
    "    \"Liberal\": build_query(LIBERAL_TERMS),\n",
    "}\n",
    "\n",
    "QUERIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1820f3-33d8-4982-bd1f-8a4cdced76c3",
   "metadata": {},
   "source": [
    "# Fetch recent post with expansions and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "830e54e1-d700-4891-80c1-70bda00a13f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 878 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     60\u001b[39m all_rows = []\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m party, q \u001b[38;5;129;01min\u001b[39;00m QUERIES.items():\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     rows = \u001b[43mfetch_recent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_TWEETS_PER_QUERY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[32m     64\u001b[39m         r[\u001b[33m\"\u001b[39m\u001b[33mparty\u001b[39m\u001b[33m\"\u001b[39m] = party\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mfetch_recent\u001b[39m\u001b[34m(query, max_results, since_iso)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fetched < max_results:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch_recent_tweets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mper_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43msince_iso\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtweet_fields\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlang\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcreated_at\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpublic_metrics\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpossibly_sensitive\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msource\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_fields\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43musername\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpublic_metrics\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverified\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpansions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauthor_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m tweepy.TooManyRequests:\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# Rate limited: wait per API guidance\u001b[39;00m\n\u001b[32m     22\u001b[39m         time.sleep(\u001b[32m60\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/politicus/.venv/lib/python3.12/site-packages/tweepy/client.py:1276\u001b[39m, in \u001b[36mClient.search_recent_tweets\u001b[39m\u001b[34m(self, query, user_auth, **params)\u001b[39m\n\u001b[32m   1184\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"search_recent_tweets( \\\u001b[39;00m\n\u001b[32m   1185\u001b[39m \u001b[33;03m    query, *, end_time=None, expansions=None, max_results=None, \\\u001b[39;00m\n\u001b[32m   1186\u001b[39m \u001b[33;03m    media_fields=None, next_token=None, place_fields=None, \\\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1273\u001b[39m \u001b[33;03m.. _Academic Research Project: https://developer.twitter.com/en/docs/projects\u001b[39;00m\n\u001b[32m   1274\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1275\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m] = query\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/2/tweets/search/recent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mend_time\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexpansions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedia.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnext_token\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mplace.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpoll.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msince_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msort_order\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstart_time\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtweet.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1282\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muntil_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTweet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_auth\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/politicus/.venv/lib/python3.12/site-packages/tweepy/client.py:129\u001b[39m, in \u001b[36mBaseClient._make_request\u001b[39m\u001b[34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_request\u001b[39m(\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m, method, route, params={}, endpoint_parameters=(), json=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    125\u001b[39m     data_type=\u001b[38;5;28;01mNone\u001b[39;00m, user_auth=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    126\u001b[39m ):\n\u001b[32m    127\u001b[39m     request_params = \u001b[38;5;28mself\u001b[39m._process_params(params, endpoint_parameters)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_auth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_type \u001b[38;5;129;01mis\u001b[39;00m requests.Response:\n\u001b[32m    133\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/politicus/.venv/lib/python3.12/site-packages/tweepy/client.py:112\u001b[39m, in \u001b[36mBaseClient.request\u001b[39m\u001b[34m(self, method, route, params, json, user_auth)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sleep_time > \u001b[32m0\u001b[39m:\n\u001b[32m    108\u001b[39m         log.warning(\n\u001b[32m    109\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRate limit exceeded. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    110\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSleeping for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    111\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(method, route, params, json, user_auth)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\\\n",
    "def fetch_recent(query, max_results=MAX_TWEETS_PER_QUERY, since_iso=SINCE):\n",
    "    # Fetch recent tweets for a given query using X API v2.\n",
    "    # Returns a list of dicts.\n",
    "    results = []\n",
    "    # Tweepy client.search_recent_tweets returns up to 100 per call\n",
    "    per_call = 100 if max_results >= 100 else max_results\n",
    "    next_token = None\n",
    "    fetched = 0\n",
    "    while fetched < max_results:\n",
    "        try:\n",
    "            resp = client.search_recent_tweets(\n",
    "                query=query,\n",
    "                max_results=per_call,\n",
    "                start_time=since_iso,\n",
    "                tweet_fields=[\"id\",\"text\",\"lang\",\"created_at\",\"public_metrics\",\"possibly_sensitive\",\"source\"],\n",
    "                user_fields=[\"username\",\"name\",\"public_metrics\",\"verified\"],\n",
    "                expansions=[\"author_id\"],\n",
    "            )\n",
    "        except tweepy.TooManyRequests:\n",
    "            # Rate limited: wait per API guidance\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        if not resp.data:\n",
    "            break\n",
    "\n",
    "        users = {u[\"id\"]: u for u in (resp.includes.get(\"users\", []) if resp.includes else [])}\n",
    "\n",
    "        for t in resp.data:\n",
    "            u = users.get(t.author_id, {}) if hasattr(t, \"author_id\") else {}\n",
    "            pm = t.public_metrics or {}\n",
    "            results.append({\n",
    "                \"id\": t.id,\n",
    "                \"created_at\": t.created_at,\n",
    "                \"text\": t.text,\n",
    "                \"lang\": t.lang,\n",
    "                \"retweets\": pm.get(\"retweet_count\"),\n",
    "                \"replies\": pm.get(\"reply_count\"),\n",
    "                \"likes\": pm.get(\"like_count\"),\n",
    "                \"quotes\": pm.get(\"quote_count\"),\n",
    "                \"author_id\": getattr(t, \"author_id\", None),\n",
    "                \"author_username\": u.get(\"username\"),\n",
    "                \"author_name\": u.get(\"name\"),\n",
    "                \"author_verified\": u.get(\"verified\"),\n",
    "                \"author_followers\": (u.get(\"public_metrics\") or {}).get(\"followers_count\"),\n",
    "                \"source\": getattr(t, \"source\", None),\n",
    "                \"possibly_sensitive\": getattr(t, \"possibly_sensitive\", None),\n",
    "            })\n",
    "        fetched += len(resp.data)\n",
    "\n",
    "        # Tweepy v4's search_recent_tweets response handles pagination internally via .meta\n",
    "        next_token = resp.meta.get(\"next_token\") if hasattr(resp, \"meta\") else None\n",
    "        if not next_token:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "# Fetch both sets\n",
    "all_rows = []\n",
    "for party, q in QUERIES.items():\n",
    "    rows = fetch_recent(q, MAX_TWEETS_PER_QUERY)\n",
    "    for r in rows:\n",
    "        r[\"party\"] = party\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "df_raw = pd.DataFrame(all_rows)\n",
    "len(df_raw), df_raw.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
